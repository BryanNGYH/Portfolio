---
title: "Spam-Ham Text Prediction"
description: "Using Natural Language Processing to classify spams"
dateString: April 2024
draft: false
tags: ["Python", "Pandas", "Numpy", "Scikit Learn", "nltk", "wordcloud", 'regex', "Naive Bayes", "Linear Support Vector Classifier", "Streamlit"]
showToc: false
weight: 202
cover:
    image: "projects/spam-ham-detection/cover.jpg"
--- 
### ðŸ”— [Github](https://github.com/BryanNGYH/Spam-Ham-Detection)


## Data Preprocessing
To train the Machine Learning model, I preprocessed and cleaned the data to ensure the model can accurately predict with consistent performance. Here are the steps that I have taken:-

- Looked for missing entries
- Checked and removed duplicated data entries 
- Used data visualization and discovered that the data is highly skewed towards ham(non-spam) messages
- Label Encoded the 'spam' column
- Transformed the 'message' column
Â  Â  - Replaced non-words characters into space
Â  Â  - Converted all texts into lowercase letter
Â  Â  - Split the texts
Â  Â  - Normalized the texts using Lemmatization
- Feature-engineered 'message' columns to extract the number of characters before and after lemmatization in a given sentence Â 
- Generated wordcloud to visualize the frequent words that appeared in spam and ham messages
- Vectorized the processed texts for model training
Â 
Â ![Spam Corpus](/projects/spam-ham-detection/spam_corpus.png)
Â 
Â ![Word Cloud of Spam Messages](/projects/spam-ham-detection/spam_wordcloud.png)

Â ![Ham Corpus](/projects/spam-ham-detection/ham_corpus.png)
Â 
Â ![Word Cloud of Ham Messages](/projects/spam-ham-detection/ham_wordcloud.png)


## Model Building
80% of the dataset was used for training and the remaining 20% was used as a test set.

Here, I tested 2 classification models to predict spam messages and texts.

- **Linear Support Vector Classifier** - Chosen as it is powerful to address non-linear classification tasks and generalizes well in high dimensional spaces, in this case, we are dealing with texts.
- **Naive Bayes** - Assumed that the word vectors are independent and can accomplish high levels of accuracy. It is also a very fast method


## Model Performance
Both models had high scores on training sets.

Â  Â  1. Linear Support Vector Classifier - 1.0
Â  Â  2. Multinomial Naive Bayes - 0.99

On test sets, both models performed well too.

Â  Â  1. Linear Support Vector Classifier:-
Â  Â  Â  Â  - Accuracy Score - 98.07
Â  Â  Â  Â  - Precision Score - 96.3
Â  Â  Â  Â  - Recall Score - 89.66
Â  Â  Â  Â  - F1 Score - 92.86
Â  Â  
Â  Â  2. Multinomial Naive Bayes:-
Â  Â  Â  Â  - Accuracy Score - 97.58
Â  Â  Â  Â  - Precision Score - 88.96
Â  Â  Â  Â  - Recall Score - 94.48
Â  Â  Â  Â  - F1 Score - 91.64

## Web Application
![Web App](/projects/spam-ham-detection/Web_App.png)

In the last step, I used the pickled model and users can access and interact with the model directly through the simple Web Application that was built with Streamlit.

Users can type or copy-paste messages in the typing space and the messages will be processed and vectorized in the background before prediction.